{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33774936",
   "metadata": {},
   "source": [
    "##  Comparaison des modèles de détection de fraude\n",
    "\n",
    "| Modèle | Seuil | AUPRC | Precision (classe 1) | Recall (classe 1) | F1-score (classe 1) | Interprétation synthétique |\n",
    "|:--------|:------:|:------:|:------------------:|:----------------:|:------------------:|:----------------------------|\n",
    "| **Régression Logistique** | 0.5 | — | 0.0698 | 0.8469 | 0.1290 | Très bon rappel mais précision catastrophique → trop d’alertes fausses (modèle trop linéaire, non adapté) |\n",
    "| **Random Forest** | 0.5 | **0.7986** | 0.8987 | 0.7245 | 0.8023 | Excellent compromis, modèle robuste et équilibré |\n",
    "| **Random Forest** | 0.1 | 0.7986 | 0.5603 | **0.8061** | 0.6611 | Recall fort mais perte de précision → bon choix si on privilégie la détection maximale |\n",
    "| **XGBoost** | 0.5 | **0.7963** | 0.8370 | **0.7857** | **0.8105** | Très bon équilibre Recall/Precision, stable et performant |\n",
    "| **XGBoost** | 0.1 | 0.7963 | 0.7647 | 0.7959 | 0.7800 | Chute modérée de la précision, modèle très robuste |\n",
    "| **Gradient Boosting (sklearn)** | 0.5 | 0.6319 | **0.9412** | 0.6531 | 0.7711 | Très précis mais manque de rappel → sous-détecte les fraudes |\n",
    "| **Gradient Boosting (sklearn)** | 0.1 | 0.6319 | 0.9143 | 0.6531 | 0.7619 | Baisse de précision sans gain en rappel → sensible au déséquilibre |\n",
    "\n",
    "---\n",
    "\n",
    "###  Interprétation globale\n",
    "\n",
    "| Classement | Modèle | Points forts |\n",
    "|:--:|:--|:--|\n",
    "|  **XGBoost** | Excellent compromis entre précision et rappel, stable et régularisé | Paramétrage plus complexe |\n",
    "|  **Random Forest** | Robuste, performant, peu de tuning | Un peu moins de détection que XGBoost |\n",
    "|  **Gradient Boosting (sklearn)** | Bon modèle académique, très précis | Moins sensible aux fraudes (déséquilibre) |\n",
    "|  **Régression Logistique** | Interprétable, simple | Trop linéaire, précision très faible |\n",
    "\n",
    "---\n",
    "\n",
    "###  Conclusion\n",
    "\n",
    "> Les modèles **Random Forest** et **XGBoost** offrent les meilleures performances globales avec un AUPRC ≈ 0.80, un bon compromis entre **rappel (détection des fraudes)** et **précision (fausses alertes limitées)**.  \n",
    "> La **régression logistique** échoue à capturer la complexité du problème, tandis que le **Gradient Boosting (sklearn)** illustre les limites d’un modèle non pondéré face au déséquilibre des classes.  \n",
    "> Pour un système antifraude opérationnel, **XGBoost** apparaît comme le meilleur choix, avec possibilité d’ajuster le seuil selon la capacité métier à traiter les alertes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
